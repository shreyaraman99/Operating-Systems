NAME: Shreya Raman
EMAIL: shreyaraman99@gmail.com	
ID: 004923456

Descriptions:

1. README: includes file descriptions and answers lab questions
2. Makefile: supports build, clean, tests, graphs, and dist
3. lab2_add.c: C source module that implements and tests a shared variable add function, implements the specified command line options, and produces the output statistics
4. lab2_list.c: C source module that implements a sorted list
5. SortedList.h: header file describing the interfaces for linked list operations
6. SortedList.c: C module that implements insert, delete, lookup, and length for a sorted doubly linked list
7. lab2_add.csv: contains results for Part-1 tests
8. lab2_list.csv: contains results for Part-2 tests
9. lab2_add.gp: sample gnuplot data reduction script for Part-1
10. lab2_list.gp: sample gnuplot data reduction script for Part-2
11. lab2_add-1.png: threads and iterations required to generate a failure
12. lab2_add-2.png: average time per operation with and without yields
13. lab2_add-3.png: average time per operation vs number of iterations
14. lab2_add-4.png: threads and iterations that can run successfully with yields under each of the synchronization options
15. lab2_add-5.png: average time per protected operation vs number of threads
16. lab2_list-1.png: average time per single threaded unprotected operation vs number of iterations
17. lab2_list-2.png: threads and iterations required to generate a failure (with and without yields)
18. lab2_list-3.png: iterations that can run (protected) without failure.
19. lab2_list-4.png: (length-adjusted) cost per operation vs the number of threads for the various synchronization options.


Questions:

2.1.1 Causing conflicts
Why does it take many iterations before errors are seen? Why does a significantly smaller number of iterations so seldom fail?

When there are fewer iterations, there is less chance of a race condition happening. As the number increases, a collision is more likely to occur and an error occurs. A smaller number of iterations seldom fail because of what I mentioned; fewer iterations means less chance of failure.


2.1.2 Cost of yielding
Why are the --yield runs so much slower? Where is the additional time going?

Running --yield gives allows a different thread to enter, so a context switch takes place. A context switch can cause a lot of overhead, therefore leading to a slower time. The additional time goes to things like saving the registers and doing the context switch.

Is it possible to get valid per-operation timings if we are using the --yield option? If so, explain how. If not, explain why not.

No it is not possible because context switches take a lot of time so the actual timings we're looking at would be affected and inaccurate.


2.1.3 Measurement errors:
Why does the average cost per operation drop with increasing iterations?

The more iterations there are, the less time is spent on context switching and creating a new thread.

If the cost per iteration is a function of the number of iterations, how do we know how many iterations to run (or what the “correct” cost is)?

The average cost per iteration decreases as we increase the iterations, so eventually we would reach this "correct" cost.


2.1.4 Costs of serialization:
Why do all of the options perform similarly for low numbers of threads?

The options perform similarly for a low number of threads because there is less overhead. The threads don't have to wait for long before executing so the performance is similar.

Why do the three protected operations slow down as the number of threads rises?

As the number of threads increase, there is more overhead and the threads take a lot of time waiting for a lock to become available.


2.2.1 Scalability of Mutex
Compare the variation in time per protected operation vs the number of threads (for mutex-protected operations) in Part-1 and Part-2, commenting on similarities/differences and offering explanations for them.

Both graphs are increasing with similar shapes, but Part-2 has a more dramatic increase than Part-1. This may be because list is more time costly than add.


2.2.2 Scalability of spin locks
Compare the variation in time per protected operation vs the number of threads for Mutex vs Spin locks, commenting on similarities/differences and offering explanations for them.

The cost of operation increases as the number of threads increase in both cases. It seems that overall, the cost per operation in spin locks grows at a rate higher than the growth for mutexes. This could be because mutex threads are put to sleep when they are not running, so they don't take extra time.