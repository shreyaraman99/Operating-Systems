NAME: Shreya Raman
EMAIL: shreyaraman99@gmail.com
ID: 004923456


Description of Files:

SortedList.h - a header file containing interfaces for linked list operations
SortedList.c - C source module that implements insert, delete, lookup, and length
lab2_list.c - implements --threads, --iterations, --yield, --sync, and -- lists
Makefile - builds the deliverable programs, output, graphs, and tarball
lab2b_list.csv - contains results for all test runs
profile.out - profiling report showing where time was spent in the un-partitioned spin-lock implementation
lab2b_1.png - throughput vs. number of threads for mutex and spin-lock synchronized list operations
lab2b_2.png - mean time per mutex wait and mean time per operation for mutex-synchronized list operations
lab2b_3.png - successful iterations vs. threads for each synchronization method
lab2b_4.png - throughput vs. number of threads for mutex synchronized partitioned lists
lab2b_5.png - throughput vs. number of threads for spin-lock-synchronized partitioned lists
testing.sh - contains specified test cases to generate CSV results
lab2_list.gp - gnuplot script to create graphs
README - description of files and answers to questions


Questions:

QUESTION 2.3.1 - CPU time in the basic list implementation:
-Where do you believe most of the CPU time is spent in the 1 and 2-thread list tests?
Most of the CPU time is spent in the list operations: inserting, deleting, looking up, and getting the length of the linked list. 

-Why do you believe these to be the most expensive parts of the code?
This is the case for the 1 and 2-thread list tests because when there are fewer threads, there is not much time spent switching between the threads, and therefore less time spent on locking mechanisms.

-Where do you believe most of the CPU time is being spent in the high-thread spin-lock tests?
Most of the CPU time is being spent waiting for the lock to be available.

-Where do you believe most of the CPU time is being spent in the high-thread mutex tests?
Most of the time is being spent on operations for the linked list like insert, delete, lookup, and length.


QUESTION 2.3.2 - Execution Profiling:
-Where (what lines of code) are consuming most of the CPU time when the spin-lock version of the list exerciser is run with a large number of threads?
Most of the CPU time is being spent on the code line of while (__sync_lock_test_and_set(&spinVar, 1));

-Why does this operation become so expensive with large numbers of threads?
When there are a large number of threads, the spin-locks wait for a lock to be available, which takes a lot of cycles.


QUESTION 2.3.3 - Mutex Wait Time:
Look at the average time per operation (vs. # threads) and the average wait-for-mutex time (vs. #threads).
-Why does the average lock-wait time rise so dramatically with the number of contending threads?
When there are more threads, more threads are waiting for a lock to become available.

-Why does the completion time per operation rise (less dramatically) with the number of contending threads?
Commpletion time rises with the number of contending threads because because when there are more threads, there are more context switches, which adds to completion time.

-How is it possible for the wait time per operation to go up faster (or higher) than the completion time per operation?
Completion time is wall time while wait timer per operation is the CPU time. This means that the wait time is more dependent on the number of threads than the completion time is, since many threads are waiting.


QUESTION 2.3.4 - Performance of Partitioned Lists
-Explain the change in performance of the synchronized methods as a function of the number of lists.
When there are more lists, throughput increases and performance is better. This is because when there are more sublists, the length of each sublist decreases and the cost of lock contention also goes down.

-Should the throughput continue increasing as the number of lists is further increased? If not, explain why not.
When there are more lists, throughput increases. However, throughput stops increasing when there exists a sublist for each element and the threads no longer have to wait. When this point is reached, have more lists does not impact the throughput.

-It seems reasonable to suggest the throughput of an N-way partitioned list should be equivalent to the throughput of a single list with fewer (1/N) threads. Does this appear to be true in the above curves? If not, explain why not.
This seems true when there is a small number of lists. But it is not true with a large number because there is an increased throughput



Notes:

My program takes a bit of time to run my testing script testing.sh, but it eventually runs and does pass the sanity check.